import { useEffect, useRef, useState } from 'react';
import { createMqttClient } from '../services/mqtt.js';
import { FeedAPI } from '../services/api.js';

const DEVICE_ID = import.meta.env.VITE_DEVICE_ID || 'petfeeder-feed-node-01';

const ManualFeed = () => {
  const [mqttStatus, setMqttStatus] = useState('offline');
  const [ackMessage, setAckMessage] = useState('');
  const [micStatus, setMicStatus] = useState('idle');
  const [loading, setLoading] = useState(false);
  const clientRef = useRef(null);
  const recognitionRef = useRef(null);

  useEffect(() => {
    const client = createMqttClient({
      deviceId: DEVICE_ID,
      onAck: (payload) => setAckMessage(payload.message || JSON.stringify(payload)),
      onStatusChange: (status) => setMqttStatus(status),
    });
    clientRef.current = client;
    return () => client?.end(true);
  }, []);

  const handleFeedNow = async () => {
    setLoading(true);
    setAckMessage('Sending feed command...');
    try {
      const { data } = await FeedAPI.manual();
      setAckMessage(data.message || 'Feed command sent successfully!');
    } catch (err) {
      setAckMessage(err.response?.data?.message || 'Failed to send feed command');
    } finally {
      setLoading(false);
    }
  };

  const handleVoiceFeed = async () => {
    // D·ª´ng listening n·∫øu ƒëang ho·∫°t ƒë·ªông
    if (micStatus === 'listening' && recognitionRef.current) {
      recognitionRef.current.stop();
      return;
    }

    // Ki·ªÉm tra xem tr√¨nh duy·ªát c√≥ h·ªó tr·ª£ Web Speech API kh√¥ng
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      setAckMessage('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng d√πng Chrome ho·∫∑c Edge.');
      return;
    }

    try {
      const recognition = new SpeechRecognition();
      recognition.lang = 'vi-VN';
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        setMicStatus('listening');
        setAckMessage('üéôÔ∏è ƒêang l·∫Øng nghe... H√£y n√≥i l·ªánh, v√≠ d·ª•: "cho ƒÉn 200 gram"');
      };

      recognition.onresult = async (event) => {
        const transcript = event.results[0][0].transcript;
        setMicStatus('processing');
        setAckMessage(`ƒê√£ nghe: "${transcript}". ƒêang g·ª≠i l·ªánh...`);

        try {
          setLoading(true);
          const { data: feedData } = await FeedAPI.voice(transcript);
          setAckMessage(feedData.message || `ƒê√£ th·ª±c hi·ªán l·ªánh: "${transcript}"`);
        } catch (err) {
          console.error('Voice feed error:', err);
          const errorMsg = err.response?.data?.message || err.response?.data?.error || 'G·ª≠i l·ªánh th·∫•t b·∫°i';
          setAckMessage(`‚ùå ${errorMsg}`);
        } finally {
          setLoading(false);
          setMicStatus('idle');
        }
      };

      recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        let errorMessage = 'L·ªói nh·∫≠n di·ªán gi·ªçng n√≥i';
        
        if (event.error === 'no-speech') {
          errorMessage = 'Kh√¥ng nghe th·∫•y gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.';
        } else if (event.error === 'audio-capture') {
          errorMessage = 'Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng ki·ªÉm tra quy·ªÅn.';
        } else if (event.error === 'not-allowed') {
          errorMessage = 'Quy·ªÅn truy c·∫≠p microphone b·ªã t·ª´ ch·ªëi.';
        }
        
        setAckMessage(errorMessage);
        setMicStatus('idle');
      };

      recognition.onend = () => {
        if (micStatus === 'listening') {
          setMicStatus('idle');
        }
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (error) {
      console.error('Error starting speech recognition:', error);
      setAckMessage('Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông nh·∫≠n di·ªán gi·ªçng n√≥i.');
      setMicStatus('idle');
    }
  };

  return (
    <div className="page">
      <div className="page__header">
        <div>
          <h2>Feed Now</h2>
          <p>Instant feeding or via voice command</p>
        </div>
        <p className="badge">MQTT: {mqttStatus}</p>
      </div>
      <section className="grid grid--2">
        <div className="card">
          <h3>Manual Feed</h3>
          <p>Dispense a single portion immediately.</p>
          <button className="btn btn--primary btn--lg" type="button" onClick={handleFeedNow} disabled={loading}>
            {loading ? 'Sending...' : 'Feed Now'}
          </button>
        </div>
        <div className="card">
          <h3>Feed by Voice</h3>
          <p>N√≥i l·ªánh nh∆∞ "cho ƒÉn 200 gram"</p>
          <button
            className={`voice-button ${micStatus === 'listening' ? 'voice-button--listening' : ''}`}
            type="button"
            onClick={handleVoiceFeed}
            disabled={loading}
          >
            <span className="voice-button__dot" aria-hidden />
            <span className="voice-button__label">
              {micStatus === 'listening' ? 'ƒêang nghe...' : micStatus === 'processing' ? 'ƒêang x·ª≠ l√Ω...' : 'Nh·∫•n ƒë·ªÉ n√≥i'}
            </span>
          </button>
          <small>Tr√¨nh duy·ªát s·∫Ω xin quy·ªÅn s·ª≠ d·ª•ng microphone.</small>
        </div>
      </section>
      {ackMessage && <p className="alert alert--info">{ackMessage}</p>}
    </div>
  );
};

export default ManualFeed;


